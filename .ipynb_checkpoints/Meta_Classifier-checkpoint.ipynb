{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final version of the classifiers and meta classifier script\n",
    "\n",
    "\n",
    "### Parameter settings\n",
    "\n",
    "First, parameters are set. The parameters are obtained from a crossvalidation performed for each seperate classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attributes from dataset that we use for classification\n",
    "# selected during crossvalidation\n",
    "\n",
    "nAttributes = ['popularity resquer id',\n",
    " 'Age',\n",
    " 'Breed1',\n",
    " 'img_pixels',\n",
    " 'description length',\n",
    " 'PhotoAmt',\n",
    " 'img_ave_contrast',\n",
    " 'Sterilized',\n",
    " 'sentiment',\n",
    " 'Breed2',\n",
    " 'img_metadata_sentiment2',\n",
    " 'FurLength',\n",
    " 'Quantity',\n",
    " 'State',\n",
    " 'Dewormed',\n",
    " 'Color1',\n",
    " 'MaturitySize',\n",
    " 'Fee',\n",
    " 'mix',\n",
    " 'vaccin',\n",
    " 'Vaccinated',\n",
    " 'Color3',\n",
    " 'cute']\n",
    "\n",
    "max_depth = 8  #max depth of decision tree\n",
    "n_estimators = 10  # number of trees in random forest\n",
    "tol = 0.01  #tolerance in (gradient/line) search in Support Vector Machine classifier, Logistic Regression\n",
    "nn = 15  # number of neighbors for K-Nearest Neighbor classifier\n",
    "xgb_params = {  #parameters for XGBoost\n",
    "    'eval_metric': 'rmse',\n",
    "    'seed': 1337,\n",
    "    'verbosity': 0,\n",
    "}   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some additional pre-processing\n",
    "\n",
    "Data is loaded and relevant attributes are obtained. A gaussian transform and normalisation transform is applied to the appropriate variables. Dataset is also converted with dummy variables for categorical attributes so that Logistic Regression can be performed. \n",
    "\n",
    "### Meta train/test set\n",
    "\n",
    "The train data is divided into a meta train and meta test set, to train and test the meta classifier respectively. 10% of the train data is used for meta testing, which helps select the best model for meta classifying.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lisa\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:902: RuntimeWarning: divide by zero encountered in log\n",
      "  llf -= N / 2.0 * np.log(np.sum((y - y_mean)**2. / N, axis=0))\n",
      "C:\\Users\\Lisa\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Lisa\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:55: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\Lisa\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:56: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn import model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv('Data/preprocessedTrain3.csv') #import data\n",
    "X = data.loc[:, data.columns != 'AdoptionSpeed'] #create X without labels\n",
    "X = X.fillna(0)\n",
    "X = X.drop('Description',axis=1) #drop non numerical values\n",
    "X = X.drop('PetID',axis=1) #\n",
    "X = X.drop('RescuerID',axis=1)\n",
    "X = X.drop('Unnamed: 0',axis=1)\n",
    "X = X.drop('Unnamed: 0.1',axis=1)\n",
    "X = X.drop('img_metadata_label',axis=1)\n",
    "X = X[nAttributes]\n",
    "y = data['AdoptionSpeed'] #label vector\n",
    "\n",
    "test = pd.read_csv('Data/preprocessedtest3.csv')\n",
    "\n",
    "\n",
    "X_test = test.drop('Description',axis=1) #drop non numerical values\n",
    "X_test = X_test.fillna(0)\n",
    "id = X_test['PetID']\n",
    "X_test = X_test.drop('PetID',axis=1) #\n",
    "X_test = X_test.drop('RescuerID',axis=1)\n",
    "X_test = X_test.drop('Unnamed: 0',axis=1)\n",
    "X_test = X_test.drop('Unnamed: 0.1',axis=1)\n",
    "\n",
    "X_test = X_test.drop('img_metadata_label',axis=1)\n",
    "X_test = X_test[nAttributes]\n",
    "\n",
    "\n",
    "non_zer0 = np.mean(X==0)==0\n",
    "zero = non_zer0[non_zer0.values==False].index\n",
    "non_zer0 = non_zer0[non_zer0.values==True].index\n",
    "\n",
    "scaler = preprocessing.PowerTransformer(method='box-cox', standardize=True).fit(X[non_zer0])\n",
    "X[non_zer0] = scaler.transform(X[non_zer0])\n",
    "X_test[non_zer0] = scaler.transform(X_test[non_zer0])\n",
    "scaler = preprocessing.StandardScaler().fit(X[zero])\n",
    "X[zero] = scaler.transform(X[zero])\n",
    "X_test[zero] = scaler.transform(X_test[zero])\n",
    "\n",
    "meta_train, meta_test, meta_y_train, meta_y_test = model_selection.train_test_split(X,y,test_size=0.5,stratify=y)\n",
    "\n",
    "\n",
    "\n",
    "Xlr_train = meta_train\n",
    "Xlr_m_test = meta_test\n",
    "Xlr_test = X_test\n",
    "dummy = ['State','Type','Breed1','Breed2','Gender','Color1','Color2','Color3','Vaccinated','Dewormed','Sterilized']\n",
    "for d in dummy:\n",
    "    if(d in nAttributes):\n",
    "        \n",
    "        train = pd.get_dummies(Xlr_train[d],prefix=d)\n",
    "        test = pd.get_dummies(Xlr_test[d],prefix=d)\n",
    "        m_test = pd.get_dummies(Xlr_m_test[d],prefix=d)\n",
    "        result = set(list(train))\n",
    "        result.intersection_update(list(test))\n",
    "        result.intersection_update(list(m_test))\n",
    "        one_hottr = train[list(result)]\n",
    "        one_hot = test[list(result)]\n",
    "        one_hotm = m_test[list(result)]\n",
    "        Xlr_train = Xlr_train.drop(d,axis = 1)\n",
    "        # Join the encoded df\n",
    "        Xlr_train = Xlr_train.join(one_hottr)\n",
    "        \n",
    "        Xlr_test = Xlr_test.drop(d,axis = 1)\n",
    "        Xlr_test = Xlr_test.join(one_hot)\n",
    "        Xlr_m_test = Xlr_m_test.drop(d,axis=1)\n",
    "        Xlr_m_test = Xlr_m_test.join(one_hotm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers\n",
    "\n",
    "The following classifiers were trained on the meta train data:\n",
    "\n",
    "+ Decision Tree classifier\n",
    "+ Random Forest classifier\n",
    "+ Logistic Regression\n",
    "+ Support Vector Machine classifier\n",
    "+ K-nearest Neighbor classifier\n",
    "+ Naive Bayes classifier\n",
    "+ XG Boost\n",
    "\n",
    "\n",
    "The predictions from these classifiers on the train data, the meta test data and the actual test data are obtained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lisa\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-rmse:1.81387\ttrain-rmse:1.80261\n",
      "Multiple eval metrics have been passed: 'train-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until train-rmse hasn't improved in 3000 rounds.\n",
      "Stopping. Best iteration:\n",
      "[1755]\teval-rmse:1.14725\ttrain-rmse:0.00861\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lisa\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:692: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "classifiers = 'DTC RF LOGREG KNN SVM SVMlinear GNB XGB ADABoost QDA'.split(sep=' ')\n",
    "predictions = np.zeros((len(X_test),len(classifiers)))\n",
    "mlp_train = np.zeros((len(meta_train),len(classifiers)))\n",
    "mlp_test = np.zeros((len(meta_test),len(classifiers)))\n",
    "\n",
    "dtc = tree.DecisionTreeClassifier(criterion='gini',max_depth=max_depth) #train decision tree\n",
    "dtc = dtc.fit(meta_train,meta_y_train)\n",
    "predictions[:,0] = dtc.predict(X_test)\n",
    "mlp_train[:,0] = dtc.predict(meta_train)\n",
    "mlp_test[:,0] = dtc.predict(meta_test)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = n_estimators)\n",
    "rf = rf.fit(meta_train, meta_y_train)\n",
    "predictions[:,1] = np.round(rf.predict(X_test),0)\n",
    "mlp_train[:,1] = np.round(rf.predict(meta_train),0)\n",
    "mlp_test[:,1] = np.round(rf.predict(meta_test),0)\n",
    "\n",
    "logreg = LogisticRegression(tol=tol,solver='liblinear',multi_class='auto')\n",
    "logreg = logreg.fit(Xlr_train, meta_y_train)\n",
    "predictions[:,2] = logreg.predict(Xlr_test)\n",
    "mlp_train[:,2] = logreg.predict(Xlr_train)\n",
    "mlp_test[:,2] = logreg.predict(Xlr_m_test)\n",
    "\n",
    "knn = KNeighborsClassifier(nn)\n",
    "knn = knn.fit(meta_train, meta_y_train)\n",
    "predictions[:,3] = knn.predict(X_test)\n",
    "mlp_train[:,3] = knn.predict(meta_train)\n",
    "mlp_test[:,3] = knn.predict(meta_test)\n",
    "\n",
    "svm = SVC(tol=tol,gamma='auto')\n",
    "svm = svm.fit(meta_train, meta_y_train)\n",
    "predictions[:,4] = svm.predict(X_test)\n",
    "mlp_train[:,4] = svm.predict(meta_train)\n",
    "mlp_test[:,4] = svm.predict(meta_test)\n",
    "\n",
    "svml = SVC(kernel=\"linear\", C=0.025)\n",
    "svml = svml.fit(meta_train,meta_y_train)\n",
    "predictions[:,5] = svml.predict(X_test)\n",
    "mlp_train[:,5] = svml.predict(meta_train)\n",
    "mlp_test[:,5] = svml.predict(meta_test)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(meta_train, meta_y_train)\n",
    "predictions[:,6] = gnb.predict(X_test)\n",
    "mlp_train[:,6] = gnb.predict(meta_train)\n",
    "mlp_test[:,6] = gnb.predict(meta_test)\n",
    "\n",
    "d_train = xgb.DMatrix(data=meta_train, label=meta_y_train, feature_names=meta_train.columns)\n",
    "d_val = xgb.DMatrix(data=meta_test,label=meta_y_test, feature_names=meta_test.columns)\n",
    "evallist = [(d_val, 'eval'), (d_train, 'train')]\n",
    "model = xgb.train(dtrain=d_train, num_boost_round=30000, evals=evallist, early_stopping_rounds=3000, verbose_eval=30000, params=xgb_params)\n",
    "predictions[:,7] = np.round(model.predict(xgb.DMatrix(X_test, feature_names=X_test.columns), ntree_limit=model.best_ntree_limit),0)\n",
    "mlp_train[:,7] = np.round(model.predict(xgb.DMatrix(meta_train, feature_names=meta_train.columns), ntree_limit=model.best_ntree_limit),0)\n",
    "mlp_test[:,7] = np.round(model.predict(xgb.DMatrix(meta_test, feature_names=meta_test.columns), ntree_limit=model.best_ntree_limit),0)\n",
    "\n",
    "abc = AdaBoostClassifier()\n",
    "abc = abc.fit(meta_train,meta_y_train)\n",
    "predictions[:,8] = abc.predict(X_test)\n",
    "mlp_train[:,8] = abc.predict(meta_train)\n",
    "mlp_test[:,8] = abc.predict(meta_test)\n",
    "\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda = qda.fit(meta_train,meta_y_train)\n",
    "predictions[:,9] = qda.predict(X_test)\n",
    "mlp_train[:,9] = qda.predict(meta_train)\n",
    "mlp_test[:,9] = qda.predict(meta_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error for DTC is: 0.5061\n",
      "Test error for DTC is: 0.6208\n",
      "\n",
      "Train error for RF is: 0.2449\n",
      "Test error for RF is: 0.6797\n",
      "\n",
      "Train error for LOGREG is: 0.5739\n",
      "Test error for LOGREG is: 0.6204\n",
      "\n",
      "Train error for KNN is: 0.5320\n",
      "Test error for KNN is: 0.6519\n",
      "\n",
      "Train error for SVM is: 0.4653\n",
      "Test error for SVM is: 0.6089\n",
      "\n",
      "Train error for SVMlinear is: 0.6227\n",
      "Test error for SVMlinear is: 0.6455\n",
      "\n",
      "Train error for GNB is: 0.6271\n",
      "Test error for GNB is: 0.6431\n",
      "\n",
      "Train error for XGB is: 0.0001\n",
      "Test error for XGB is: 0.6769\n",
      "\n",
      "Train error for ADABoost is: 0.5826\n",
      "Test error for ADABoost is: 0.6068\n",
      "\n",
      "Train error for QDA is: 0.7709\n",
      "Test error for QDA is: 0.7720\n",
      "\n",
      "In total, 100.00% of the meta training set is classified correctly by at least one classifier\n",
      "In total, 85.05% of the meta test set is classified correctly by at least one classifier\n"
     ]
    }
   ],
   "source": [
    "correct = np.zeros((len(meta_train),len(classifiers)))\n",
    "correct_test = np.zeros((len(meta_test),len(classifiers)))\n",
    "for i in range(len(classifiers)):\n",
    "    err = 1-np.mean(mlp_train[:,i]==meta_y_train)\n",
    "    print('Train error for {} is: {:.4f}'.format(classifiers[i],err))\n",
    "    err = 1-np.mean(mlp_test[:,i]==meta_y_test)\n",
    "    print('Test error for {} is: {:.4f}'.format(classifiers[i],err))\n",
    "    print()\n",
    "    correct[:,i] = mlp_train[:,i] == meta_y_train\n",
    "    correct_test[:,i] = mlp_test[:,i] == meta_y_test\n",
    "    if(min(mlp_train[:,i])<0):\n",
    "        print(classifiers[i])\n",
    "        mlp_train[mlp_train[:,i]<0,i] = 0\n",
    "    if(np.any(np.isnan(mlp_train[:,i]))):\n",
    "        print(classifiers[i])\n",
    "        \n",
    "    if(max(mlp_train[:,i]>4)):\n",
    "        print(classifiers[i])\n",
    "        mlp_train[mlp_train[:,i]>4,i] = 4\n",
    "    if(np.all(np.isfinite(mlp_train[:,i]))==0):\n",
    "        print(classifiers[i])\n",
    "        \n",
    "correctdf = pd.DataFrame(correct)\n",
    "correct_testdf = pd.DataFrame(correct_test)\n",
    "print('In total, {:.2f}% of the meta training set is classified correctly by at least one classifier'.format(correctdf.max(axis=1).mean()*100))\n",
    "print('In total, {:.2f}% of the meta test set is classified correctly by at least one classifier'.format(correct_testdf.max(axis=1).mean()*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta classifier training\n",
    "\n",
    "We map the set of predictions from the different classifiers to a single prediction. To find the optimal weights of the contributions that each classifier should have, we train a Multilayer Perceptron on the meta test set. The model that we select for the actual test data prediction is the model that \n",
    "\n",
    "1. has the lowest meta test error\n",
    "2. results in a label distribution for the test set that's closest to the distribution in the complete training data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 test accuracy: 0.3942\n",
      "Layer 1 lowest SSE hist: 0.0803\n",
      "\n",
      "Layer 2 test accuracy: 0.3979\n",
      "Layer 2 lowest SSE hist: 0.0703\n",
      "\n",
      "Layer 3 test accuracy: 0.3990\n",
      "Layer 3 lowest SSE hist: 0.0537\n",
      "\n",
      "Layer 4 test accuracy: 0.4043\n",
      "Layer 4 lowest SSE hist: 0.0561\n",
      "\n",
      "Layer 5 test accuracy: 0.4019\n",
      "Layer 5 lowest SSE hist: 0.0496\n",
      "\n",
      "Layer 6 test accuracy: 0.4054\n",
      "Layer 6 lowest SSE hist: 0.0539\n",
      "\n",
      "Layer 7 test accuracy: 0.4144\n",
      "Layer 7 lowest SSE hist: 0.0582\n",
      "\n",
      "Layer 8 test accuracy: 0.4143\n",
      "Layer 8 lowest SSE hist: 0.0575\n",
      "\n",
      "Layer 9 test accuracy: 0.4106\n",
      "Layer 9 lowest SSE hist: 0.0498\n",
      "\n",
      "Layer 10 test accuracy: 0.4166\n",
      "Layer 10 lowest SSE hist: 0.0469\n",
      "\n",
      "Layer 11 test accuracy: 0.4090\n",
      "Layer 11 lowest SSE hist: 0.0529\n",
      "\n",
      "Layer 12 test accuracy: 0.4182\n",
      "Layer 12 lowest SSE hist: 0.0481\n",
      "\n",
      "Layer 13 test accuracy: 0.4254\n",
      "Layer 13 lowest SSE hist: 0.0506\n",
      "\n",
      "Layer 14 test accuracy: 0.4210\n",
      "Layer 14 lowest SSE hist: 0.0572\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def hist(y):\n",
    "    histy = np.zeros((5,))\n",
    "    for i in range(0,5):\n",
    "        histy[i] = np.mean(y==i)\n",
    "    return histy\n",
    "\n",
    "def sse_hist(h1,h2,weight=[1,1,1,1,1]):\n",
    "    sse = 0\n",
    "    for i in range(0,5):\n",
    "        sse = sse + weight[i]*(h1[i] - h2[i])**2\n",
    "    return sse\n",
    "#%%\n",
    "histy = hist(y)     \n",
    "\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "models = []\n",
    "accuracy = []\n",
    "models_sse = []\n",
    "sse = []\n",
    "for i in range(1,15):\n",
    "    model_j = []\n",
    "    score_j = []\n",
    "    sse_j = []\n",
    "    for j in range(0,10):\n",
    "        clf = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(i,))\n",
    "        clf.fit(mlp_test, meta_y_test)\n",
    "        model_j.append(clf)\n",
    "        score_j.append(clf.score(mlp_test,meta_y_test))\n",
    "        hist_est = hist(clf.predict(predictions))\n",
    "        weights = 1-histy\n",
    "        sse_j.append(sse_hist(hist_est,histy,weight=weights))\n",
    "        \n",
    "    \n",
    "    print(\"Layer {} test accuracy: {:.4f}\".format(i,max(score_j)))\n",
    "    print(\"Layer {} lowest SSE hist: {:.4f}\".format(i,min(sse_j)))\n",
    "    print()\n",
    "    \n",
    "    models.append(model_j[np.argmax(score_j)])\n",
    "    accuracy.append(max(score_j))\n",
    "    sse.append(sse_j[np.argmax(score_j)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of hlayers test acc = 13\n",
      "Best number of hlayers hist sse = 10\n",
      "Best number of hlayers total = 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f5198a44e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f51a687dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_acc = np.argmax(accuracy)\n",
    "print('Best number of hlayers test acc = {}'.format(model_acc+1)) \n",
    "model_sse = np.argmin(sse)\n",
    "print('Best number of hlayers hist sse = {}'.format(model_sse+1)) \n",
    "s = [accuracy[i]-sse[i] for i in range(0,7)]\n",
    "model = np.argmax(s)\n",
    "print('Best number of hlayers total = {}'.format(model+1)) \n",
    "\n",
    "clf = models[model]\n",
    "\n",
    "y_est = clf.predict(predictions)\n",
    "\n",
    "submission = pd.DataFrame(index=X_test.index)\n",
    "submission['PetID'] = id\n",
    "submission['AdoptionSpeed'] = y_est\n",
    "submission['AdoptionSpeed'] = submission['AdoptionSpeed'].astype(int)\n",
    "submission.to_csv('submission.csv',index=False)\n",
    "\n",
    "\n",
    "histy = y.hist()\n",
    "plt.title('Distribution of labels in Training set')\n",
    "plt.show()\n",
    "plt.title('Distribution of labels in predictions on Test set')\n",
    "hist2 = submission.hist()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
