{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final version of the classifiers and meta classifier script\n",
    "\n",
    "\n",
    "### Parameter settings\n",
    "\n",
    "First, parameters are set. The parameters are obtained from a crossvalidation performed for each seperate classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attributes from dataset that we use for classification\n",
    "\n",
    "nAttributes = ['Age', 'popularity resquer id', 'Breed1', 'img_pixels', 'PhotoAmt', 'Sterilized', 'description length',\n",
    "               'img_ave_contrast', 'Breed2', 'Quantity', 'Gender', 'img_metadata_sentiment2', 'beaut', 'MaturitySize',\n",
    "               'State',  'Color3', 'vaccin', 'abandon', 'Vaccinated', 'Fee', 'indoor', 'cute', 'great']\n",
    "\n",
    "\n",
    "max_depth = 8  #max depth of decision tree\n",
    "n_estimators = 10  # number of trees in random forest\n",
    "tol = 0.01  #tolerance in (gradient/line) search in Support Vector Machine classifier, Logistic Regression\n",
    "nn = 15  # number of neighbors for K-Nearest Neighbor classifier\n",
    "xgb_params = {  #parameters for XGBoost\n",
    "    'eval_metric': 'rmse',\n",
    "    'seed': 1337,\n",
    "    'verbosity': 0,\n",
    "}   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some additional pre-processing\n",
    "\n",
    "Data is loaded and relevant attributes are obtained. A gaussian transform and normalisation transform is applied to the appropriate variables. Dataset is also converted with dummy variables for categorical attributes so that Logistic Regression can be performed. \n",
    "\n",
    "### Meta train/test set\n",
    "\n",
    "The train data is divided into a meta train and meta test set, to train and test the meta classifier respectively. 10% of the train data is used for meta testing, which helps select the best model for meta classifying.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lisa\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:902: RuntimeWarning: divide by zero encountered in log\n",
      "  llf -= N / 2.0 * np.log(np.sum((y - y_mean)**2. / N, axis=0))\n",
      "C:\\Users\\Lisa\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Lisa\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:53: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "C:\\Users\\Lisa\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:54: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn import model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "\n",
    "data = pd.read_csv('Data/preprocessedTrain3.csv') #import data\n",
    "X = data.loc[:, data.columns != 'AdoptionSpeed'] #create X without labels\n",
    "X = X.fillna(0)\n",
    "X = X.drop('Description',axis=1) #drop non numerical values\n",
    "X = X.drop('PetID',axis=1) #\n",
    "X = X.drop('RescuerID',axis=1)\n",
    "X = X.drop('Unnamed: 0',axis=1)\n",
    "X = X.drop('Unnamed: 0.1',axis=1)\n",
    "X = X.drop('img_metadata_label',axis=1)\n",
    "X = X[nAttributes]\n",
    "y = data['AdoptionSpeed'] #label vector\n",
    "\n",
    "test = pd.read_csv('Data/preprocessedtest3.csv')\n",
    "\n",
    "\n",
    "X_test = test.drop('Description',axis=1) #drop non numerical values\n",
    "X_test = X_test.fillna(0)\n",
    "id = X_test['PetID']\n",
    "X_test = X_test.drop('PetID',axis=1) #\n",
    "X_test = X_test.drop('RescuerID',axis=1)\n",
    "X_test = X_test.drop('Unnamed: 0',axis=1)\n",
    "X_test = X_test.drop('Unnamed: 0.1',axis=1)\n",
    "\n",
    "X_test = X_test.drop('img_metadata_label',axis=1)\n",
    "X_test = X_test[nAttributes]\n",
    "\n",
    "\n",
    "non_zer0 = np.mean(X==0)==0\n",
    "zero = non_zer0[non_zer0.values==False].index\n",
    "non_zer0 = non_zer0[non_zer0.values==True].index\n",
    "\n",
    "scaler = preprocessing.PowerTransformer(method='box-cox', standardize=True).fit(X[non_zer0])\n",
    "X[non_zer0] = scaler.transform(X[non_zer0])\n",
    "X_test[non_zer0] = scaler.transform(X_test[non_zer0])\n",
    "scaler = preprocessing.StandardScaler().fit(X[zero])\n",
    "X[zero] = scaler.transform(X[zero])\n",
    "X_test[zero] = scaler.transform(X_test[zero])\n",
    "\n",
    "meta_train, meta_test, meta_y_train, meta_y_test = model_selection.train_test_split(X,y,test_size=0.1,stratify=y)\n",
    "\n",
    "\n",
    "\n",
    "Xlr_train = meta_train\n",
    "Xlr_m_test = meta_test\n",
    "Xlr_test = X_test\n",
    "dummy = ['State','Type','Breed1','Breed2','Gender','Color1','Color2','Color3','Vaccinated','Dewormed','Sterilized']\n",
    "for d in dummy:\n",
    "    if(d in nAttributes):\n",
    "        \n",
    "        train = pd.get_dummies(Xlr_train[d],prefix=d)\n",
    "        test = pd.get_dummies(Xlr_test[d],prefix=d)\n",
    "        m_test = pd.get_dummies(Xlr_m_test[d],prefix=d)\n",
    "        result = set(list(train))\n",
    "        result.intersection_update(list(test))\n",
    "        result.intersection_update(list(m_test))\n",
    "        one_hottr = train[list(result)]\n",
    "        one_hot = test[list(result)]\n",
    "        one_hotm = m_test[list(result)]\n",
    "        Xlr_train = Xlr_train.drop(d,axis = 1)\n",
    "        # Join the encoded df\n",
    "        Xlr_train = Xlr_train.join(one_hottr)\n",
    "        \n",
    "        Xlr_test = Xlr_test.drop(d,axis = 1)\n",
    "        Xlr_test = Xlr_test.join(one_hot)\n",
    "        Xlr_m_test = Xlr_m_test.drop(d,axis=1)\n",
    "        Xlr_m_test = Xlr_m_test.join(one_hotm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers\n",
    "\n",
    "The following classifiers were trained on the meta train data:\n",
    "\n",
    "+ Decision Tree classifier\n",
    "+ Random Forest classifier\n",
    "+ Logistic Regression\n",
    "+ Support Vector Machine classifier\n",
    "+ K-nearest Neighbor classifier\n",
    "+ Naive Bayes classifier\n",
    "+ XG Boost\n",
    "\n",
    "\n",
    "The predictions from these classifiers on the train data, the meta test data and the actual test data are obtained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lisa\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-rmse:1.81189\ttrain-rmse:1.80592\n",
      "Multiple eval metrics have been passed: 'train-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until train-rmse hasn't improved in 3000 rounds.\n",
      "[3000]\teval-rmse:1.11592\ttrain-rmse:0.006036\n",
      "[6000]\teval-rmse:1.11594\ttrain-rmse:0.003764\n",
      "Stopping. Best iteration:\n",
      "[3317]\teval-rmse:1.11594\ttrain-rmse:0.003764\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = 'DTC RF LOGREG KNN SVM GNB XGB'.split(sep=' ')\n",
    "predictions = np.zeros((len(X_test),len(classifiers)))\n",
    "mlp_train = np.zeros((len(meta_train),len(classifiers)))\n",
    "mlp_test = np.zeros((len(meta_test),len(classifiers)))\n",
    "\n",
    "dtc = tree.DecisionTreeClassifier(criterion='gini',max_depth=max_depth) #train decision tree\n",
    "dtc = dtc.fit(meta_train,meta_y_train)\n",
    "predictions[:,0] = dtc.predict(X_test)\n",
    "mlp_train[:,0] = dtc.predict(meta_train)\n",
    "mlp_test[:,0] = dtc.predict(meta_test)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators = n_estimators) #train random forest\n",
    "rf = rf.fit(meta_train, meta_y_train)\n",
    "predictions[:,1] = np.round(rf.predict(X_test),0)\n",
    "mlp_train[:,1] = np.round(rf.predict(meta_train),0)\n",
    "mlp_test[:,1] = np.round(rf.predict(meta_test),0)\n",
    "\n",
    "logreg = LogisticRegression(tol=tol,solver='liblinear',multi_class='auto')  # train logistic regressor\n",
    "logreg = logreg.fit(Xlr_train, meta_y_train)\n",
    "predictions[:,2] = logreg.predict(Xlr_test)\n",
    "mlp_train[:,2] = logreg.predict(Xlr_train)\n",
    "mlp_test[:,2] = logreg.predict(Xlr_m_test)\n",
    "\n",
    "knn = KNeighborsClassifier(nn)   # train KNN\n",
    "knn = knn.fit(meta_train, meta_y_train)\n",
    "predictions[:,3] = knn.predict(X_test)\n",
    "mlp_train[:,3] = knn.predict(meta_train)\n",
    "mlp_test[:,3] = knn.predict(meta_test)\n",
    "\n",
    "svm = SVC(tol=tol,gamma='auto')   # train SVM\n",
    "svm = svm.fit(meta_train, meta_y_train)\n",
    "predictions[:,4] = svm.predict(X_test)\n",
    "mlp_train[:,4] = svm.predict(meta_train)\n",
    "mlp_test[:,4] = svm.predict(meta_test)\n",
    "\n",
    "gnb = GaussianNB()   # train Naive Bayes\n",
    "gnb = gnb.fit(meta_train, meta_y_train)\n",
    "predictions[:,5] = gnb.predict(X_test)\n",
    "mlp_train[:,5] = dtc.predict(meta_train)\n",
    "mlp_test[:,5] = knn.predict(meta_test)\n",
    "\n",
    "d_train = xgb.DMatrix(data=meta_train, label=meta_y_train, feature_names=meta_train.columns)  # train XG boost\n",
    "d_val = xgb.DMatrix(data=meta_test,label=meta_y_test, feature_names=meta_test.columns)\n",
    "evallist = [(d_val, 'eval'), (d_train, 'train')]\n",
    "model = xgb.train(dtrain=d_train, num_boost_round=30000, evals=evallist, early_stopping_rounds=3000, verbose_eval=3000, params=xgb_params)\n",
    "predictions[:,6] = np.round(model.predict(xgb.DMatrix(X_test, feature_names=X_test.columns), ntree_limit=model.best_ntree_limit),0)\n",
    "mlp_train[:,6] = np.round(model.predict(xgb.DMatrix(meta_train, feature_names=meta_train.columns), ntree_limit=model.best_ntree_limit),0)\n",
    "mlp_test[:,6] = np.round(model.predict(xgb.DMatrix(meta_test, feature_names=meta_test.columns), ntree_limit=model.best_ntree_limit),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error for DTC is: 0.5399\n",
      "Test error for DTC is: 0.6100\n",
      "\n",
      "Train error for RF is: 0.2429\n",
      "Test error for RF is: 0.6733\n",
      "\n",
      "Train error for LOGREG is: 0.5883\n",
      "Test error for LOGREG is: 0.5993\n",
      "\n",
      "Train error for KNN is: 0.5306\n",
      "Test error for KNN is: 0.6433\n",
      "\n",
      "Train error for SVM is: 0.5058\n",
      "Test error for SVM is: 0.6067\n",
      "\n",
      "Train error for GNB is: 0.5399\n",
      "Test error for GNB is: 0.6433\n",
      "\n",
      "Train error for XGB is: 0.0000\n",
      "Test error for XGB is: 0.6580\n",
      "\n",
      "In total, 100.00% of the meta training set is classified correctly by at least one classifier\n",
      "In total, 76.67% of the meta test set is classified correctly by at least one classifier\n"
     ]
    }
   ],
   "source": [
    "correct = np.zeros((len(meta_train),len(classifiers)))\n",
    "correct_test = np.zeros((len(meta_test),len(classifiers)))\n",
    "for i in range(len(classifiers)):\n",
    "    err = 1-np.mean(mlp_train[:,i]==meta_y_train)\n",
    "    print('Train error for {} is: {:.4f}'.format(classifiers[i],err))\n",
    "    err = 1-np.mean(mlp_test[:,i]==meta_y_test)\n",
    "    print('Test error for {} is: {:.4f}'.format(classifiers[i],err))\n",
    "    print()\n",
    "    correct[:,i] = mlp_train[:,i] == meta_y_train\n",
    "    correct_test[:,i] = mlp_test[:,i] == meta_y_test\n",
    "\n",
    "        \n",
    "correctdf = pd.DataFrame(correct)\n",
    "correct_testdf = pd.DataFrame(correct_test)\n",
    "print('In total, {:.2f}% of the meta training set is classified correctly by at least one classifier'.format(correctdf.max(axis=1).mean()*100))\n",
    "print('In total, {:.2f}% of the meta test set is classified correctly by at least one classifier'.format(correct_testdf.max(axis=1).mean()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta classifier training\n",
    "\n",
    "We map the set of predictions from the different classifiers to a single prediction. To find the optimal weights of the contributions that each classifier should have, we train a Multilayer Perceptron on the meta test set. The model that we select for the actual test data prediction is the model that \n",
    "\n",
    "1. has the lowest meta test error\n",
    "2. results in a label distribution for the test set that's closest to the distribution in the complete training data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 meta test accuracy: 0.4087\n",
      "Layer 1 lowest SSE hist: 0.0782\n",
      "\n",
      "Layer 2 meta test accuracy: 0.4087\n",
      "Layer 2 lowest SSE hist: 0.0768\n",
      "\n",
      "Layer 3 meta test accuracy: 0.4153\n",
      "Layer 3 lowest SSE hist: 0.0559\n",
      "\n",
      "Layer 4 meta test accuracy: 0.4260\n",
      "Layer 4 lowest SSE hist: 0.0673\n",
      "\n",
      "Layer 5 meta test accuracy: 0.4240\n",
      "Layer 5 lowest SSE hist: 0.0709\n",
      "\n",
      "Layer 6 meta test accuracy: 0.4360\n",
      "Layer 6 lowest SSE hist: 0.0517\n",
      "\n",
      "Layer 7 meta test accuracy: 0.4460\n",
      "Layer 7 lowest SSE hist: 0.0317\n",
      "\n",
      "Layer 8 meta test accuracy: 0.4307\n",
      "Layer 8 lowest SSE hist: 0.0663\n",
      "\n",
      "Layer 9 meta test accuracy: 0.4327\n",
      "Layer 9 lowest SSE hist: 0.0567\n",
      "\n",
      "Best number of hlayers test accuracy = 7\n",
      "Best number of hlayers hist sse = 7\n",
      "Best number of hlayers total = 7\n"
     ]
    }
   ],
   "source": [
    "def hist(y):\n",
    "    ''' Compute distribution over labels\n",
    "    '''\n",
    "    histy = np.zeros((5,))\n",
    "    for i in range(0,5):\n",
    "        histy[i] = np.mean(y==i)\n",
    "    return histy\n",
    "\n",
    "def sse_hist(h1,h2,weight=[1,1,1,1,1]):\n",
    "    ''' Compute summed square error of the difference between two label distributions\n",
    "    '''\n",
    "    sse = 0\n",
    "    for i in range(0,5):\n",
    "        sse = sse + weight[i]*(h1[i] - h2[i])**2\n",
    "    return sse\n",
    "\n",
    "histy = hist(y)     \n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "models = []\n",
    "accuracy = []\n",
    "models_sse = []\n",
    "sse = []\n",
    "for i in range(1,10):\n",
    "    model_j = []\n",
    "    score_j = []\n",
    "    sse_j = []\n",
    "    for j in range(0,10):  # reset model 10 times to overcome random initialisation biases \n",
    "        clf = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(i,))\n",
    "        clf.fit(mlp_test, meta_y_test)\n",
    "        model_j.append(clf)\n",
    "        score_j.append(clf.score(mlp_test,meta_y_test))\n",
    "        hist_est = hist(clf.predict(predictions))\n",
    "        weights = 1-histy\n",
    "        sse_j.append(sse_hist(hist_est,histy,weight=weights))\n",
    "        \n",
    "    \n",
    "    print(\"Layer {} meta test accuracy: {:.4f}\".format(i,max(score_j)))\n",
    "    print(\"Layer {} lowest SSE hist: {:.4f}\".format(i,min(sse_j)))\n",
    "    print()\n",
    "    \n",
    "    models.append(model_j[np.argmax(score_j)])\n",
    "    accuracy.append(max(score_j))\n",
    "    sse.append(sse_j[np.argmax(score_j)])\n",
    "    \n",
    "    \n",
    "#%%\n",
    "model_acc = np.argmax(accuracy)\n",
    "print('Best number of hlayers test accuracy = {}'.format(model_acc+1)) \n",
    "model_sse = np.argmin(sse)\n",
    "print('Best number of hlayers hist sse = {}'.format(model_sse+1)) \n",
    "s = [accuracy[i]-sse[i] for i in range(0,7)]\n",
    "model = np.argmax(s)\n",
    "print('Best number of hlayers total = {}'.format(model+1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x294436b2ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29456e15400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf = models[model]\n",
    "y_est = clf.predict(predictions)\n",
    "\n",
    "submission = pd.DataFrame(index=X_test.index)\n",
    "submission['PetID'] = id\n",
    "submission['AdoptionSpeed'] = y_est\n",
    "submission['AdoptionSpeed'] = submission['AdoptionSpeed'].astype(int)\n",
    "submission.to_csv('submission.csv',index=False)\n",
    "\n",
    "histy = y.hist()\n",
    "submission.hist()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
